{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def number_of_people(sentence):\n",
    "    active_sequence = False\n",
    "    count = 0\n",
    "    for tag in sentence.ner_tags:\n",
    "        if tag == 'PERSON' and not active_sequence:\n",
    "            active_sequence = True\n",
    "            count += 1\n",
    "        elif tag != 'PERSON' and active_sequence:\n",
    "            active_sequence = False\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from snorkel.lf_helpers import get_left_tokens, get_right_tokens, get_between_tokens, get_text_between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titles={'Representative','Assistant','Special Assistant','diplomat','official','government official','AMBASSADOR','Chancellor','Sen','Senator','Congresswoman','Congressman','Chief of Staff','mayor','Chairman','Attorney General','General',' Gen','Vice President','VP','President','dictator','Secretary','Assistant Secretary','Defense Secretary','Secretary of State','Secretary General','Gov.','Governer','Speaker','House Speaker','Democrat','Republican','PM','Minister','foreign minister','Prime Minister','ambassador','amb','Founder','Co-Founder','Author','chief executive','CEO','head of','editor','reporter','publisher','anchor','adviser','Chairman','chairwoman','chair','Rep.','columnist','leader','militant','director','deputy director','Executive Director','professor','Navy SEAL','talk show host','activist','specialist'}\n",
    "\n",
    "def LF_political_title(c):\n",
    "    return 1 if len(titles.intersection(set(get_between_tokens(c)))) > 0 else 0\n",
    "\n",
    "\n",
    "\n",
    "def LF_title_left_window(c):\n",
    "    if len(titles.intersection(set(get_left_tokens(c[0], window=2)))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "        \n",
    "def LF_title_right_window(c):\n",
    "    if len(titles.intersection(set(get_right_tokens(c[0], window=2)))) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def LF_no_title_in_sentence(c):\n",
    "    return -1 if len(titles.intersection(set(c[0].parent.words))) == 0 else 0\n",
    "\n",
    "\n",
    "LFs = [LF_political_title, LF_title_left_window, LF_title_right_window, LF_no_title_in_sentence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File or directory not found: data/clinton_train.tsv",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-bb7c868924ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpusParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_parser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msent_parser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'time corpus = cp.parse_corpus(session, \"Emails Training\")'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mmagic\u001b[0;34m(self, arg_s)\u001b[0m\n\u001b[1;32m   2161\u001b[0m         \u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2162\u001b[0m         \u001b[0mmagic_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmagic_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mESC_MAGIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2163\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2165\u001b[0m     \u001b[0;31m#-------------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line)\u001b[0m\n\u001b[1;32m   2082\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2083\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2084\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2085\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2086\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/anaconda/lib/python2.7/site-packages/IPython/core/magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/anaconda/lib/python2.7/site-packages/IPython/core/magics/execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1175\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1177\u001b[0;31m             \u001b[0;32mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/Downloads/snorkel/snorkel/parser.py\u001b[0m in \u001b[0;36mparse_corpus\u001b[0;34m(self, session, name)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_docs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mpb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_docs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mpb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/Downloads/snorkel/snorkel/parser.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     63\u001b[0m                   \u001b[0;32mand\u001b[0m \u001b[0mpossibly\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0mof\u001b[0m \u001b[0mother\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m             \u001b[0mfile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/Downloads/snorkel/snorkel/parser.py\u001b[0m in \u001b[0;36m_get_files\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File or directory not found: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTSVDocParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDocParser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File or directory not found: data/clinton_train.tsv"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "import os\n",
    "\n",
    "from snorkel.parser import TSVDocParser\n",
    "doc_parser = TSVDocParser(path=\"data/clinton_train.tsv\")\n",
    "\n",
    "from snorkel.parser import SentenceParser\n",
    "\n",
    "sent_parser = SentenceParser()\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "cp = CorpusParser(doc_parser, sent_parser)\n",
    "%time corpus = cp.parse_corpus(session, \"Emails Training\")\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKIPPED A MALFORMED SENTENCE!\n",
      "Number of documents: 5393\n",
      "CPU times: user 58.8 s, sys: 1.91 s, total: 1min\n",
      "Wall time: 6min 46s\n"
     ]
    }
   ],
   "source": [
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()\n",
    "import os\n",
    "\n",
    "from snorkel.parser import TSVDocParser\n",
    "doc_parser = TSVDocParser(path=\"data/clinton_train.tsv\")\n",
    "\n",
    "from snorkel.parser import SentenceParser\n",
    "\n",
    "sent_parser = SentenceParser()\n",
    "from snorkel.parser import CorpusParser\n",
    "\n",
    "cp = CorpusParser(doc_parser, sent_parser)\n",
    "%time corpus = cp.parse_corpus(session, \"Emails Training\")\n",
    "session.add(corpus)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 675\n",
      "CPU times: user 6.72 s, sys: 178 ms, total: 6.9 s\n",
      "Wall time: 47.8 s\n",
      "Number of documents: 674\n",
      "CPU times: user 7.58 s, sys: 220 ms, total: 7.8 s\n",
      "Wall time: 52.9 s\n"
     ]
    }
   ],
   "source": [
    "for name, path in [('Emails Development', 'data/clinton_dev.tsv'),\n",
    "                   ('Emails Test', 'data/clinton_test.tsv')]:\n",
    "    doc_parser.path=path\n",
    "    %time corpus = cp.parse_corpus(session, name)\n",
    "    session.commit()\n",
    "\n",
    "sentences = set()\n",
    "for document in corpus:\n",
    "    for sentence in document.sentences:\n",
    "        if number_of_people(sentence) < 5:\n",
    "            sentences.add(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 28.2 s, sys: 4.87 s, total: 33.1 s\n",
      "Wall time: 29.4 s\n",
      "Number of candidates: 670\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import candidate_subclass\n",
    "\n",
    "Title = candidate_subclass('Person_Org', ['person1', 'organization'])\n",
    "\n",
    "from snorkel.candidates import Ngrams\n",
    "\n",
    "ngrams = Ngrams(n_max=3)\n",
    "\n",
    "from snorkel.matchers import PersonMatcher\n",
    "\n",
    "from snorkel.matchers import OrganizationMatcher\n",
    "\n",
    "person_matcher = PersonMatcher(longest_match_only=True)\n",
    "\n",
    "org_matcher = OrganizationMatcher(longest_match_only=True)\n",
    "\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "\n",
    "ce = CandidateExtractor(Title, [ngrams, ngrams], [person_matcher, org_matcher],\n",
    "                        symmetric_relations=False, nested_relations=False, self_relations=False)\n",
    "\t\t\t\t\t\t\n",
    "%time c = ce.extract(sentences, 'Emails Training Candidates', session)\n",
    "print \"Number of candidates:\", len(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "session.add(c)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 26.9 s, sys: 5.04 s, total: 31.9 s\n",
      "Wall time: 28.1 s\n",
      "[========================================] 100%\n",
      "\n",
      "CPU times: user 26.7 s, sys: 5 s, total: 31.7 s\n",
      "Wall time: 27.9 s\n"
     ]
    }
   ],
   "source": [
    "for corpus_name in ['Emails Development', 'Emails Test']:\n",
    "    #corpus = session.query(Corpus).filter(Corpus.name == corpus_name).one()\n",
    "    sentences = set()\n",
    "    for document in corpus:\n",
    "        for sentence in document.sentences:\n",
    "            if number_of_people(sentence) < 5:\n",
    "                sentences.add(sentence)\n",
    "    \n",
    "    %time c = ce.extract(sentences, corpus_name + ' Candidates', session)\n",
    "    session.add(c)\n",
    "session.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named treedlib",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-bc44228d6a43>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidateSet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCandidateSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'Emails Development Candidates'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotations\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFeatureManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfeature_manager\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeatureManager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/Downloads/snorkel/snorkel/annotations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mannotation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotation_key_set_annotation_key_association\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0massoc_table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_ORM_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProgressBar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_span_feats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msqlalchemy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mobject_session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/vmangipudi/Downloads/snorkel/snorkel/features.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCandidateSet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSpan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'SNORKELHOME'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'treedlib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtreedlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompile_relation_feature_generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtree_structs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcorenlp_to_xmltree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_as_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named treedlib"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'Emails Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'Emails Development Candidates').one()\n",
    "\n",
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "\n",
    "%time F_train = feature_manager.create(session, c, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Feature matrix...\n",
      "CPU times: user 2min 36s, sys: 956 ms, total: 2min 37s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "train = session.query(CandidateSet).filter(CandidateSet.name == 'Emails Training Candidates').one()\n",
    "dev = session.query(CandidateSet).filter(CandidateSet.name == 'Emails Development Candidates').one()\n",
    "\n",
    "from snorkel.annotations import FeatureManager\n",
    "\n",
    "feature_manager = FeatureManager()\n",
    "\n",
    "%time F_train = feature_manager.create(session, c, 'Train Features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[========================================] 100%\n",
      "\n",
      "Loading sparse Label matrix...\n",
      "CPU times: user 7.05 s, sys: 593 ms, total: 7.65 s\n",
      "Wall time: 7.19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vmangipudi/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:1350: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training marginals (!= 0.5):\t670\n",
      "Features:\t\t\t4\n",
      "================================================================================\n",
      "Begin training for rate=1e-05, mu=1e-06\n",
      "\tLearning epoch = 0\tGradient mag. = 0.104464\n",
      "\tLearning epoch = 250\tGradient mag. = 0.109955\n",
      "\tLearning epoch = 500\tGradient mag. = 0.109949\n",
      "\tLearning epoch = 750\tGradient mag. = 0.109942\n",
      "Final gradient magnitude for rate=1e-05, mu=1e-06: 0.110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99997704,  0.99988309,  1.00027466,  0.99894211])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "\n",
    "label_manager = LabelManager()\n",
    "\n",
    "%time L_train = label_manager.create(session, c, 'LF Labels', f=LFs)\n",
    "L_train\n",
    "\n",
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "gen_model = NaiveBayes()\n",
    "gen_model.train(L_train, n_iter=1000, rate=1e-5)\n",
    "\n",
    "\n",
    "gen_model.save(session, 'Generative Params')\n",
    "train_marginals = gen_model.marginals(L_train)\n",
    "gen_model.w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name RandomSearch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-9c8433b1ae86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogReg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miter_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name RandomSearch"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "iter_param = ListParameter('n_iter', [250, 500, 1000, 2000])\n",
    "rate_param = RangeParameter('rate', 1e-4, 1e-2, step=0.75, log_base=10)\n",
    "reg_param  = RangeParameter('mu', 1e-8, 1e-2, step=1, log_base=10)\n",
    "\n",
    "disc_model = LogReg()\n",
    "\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name RandomSearch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-9c8433b1ae86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogReg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miter_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name RandomSearch"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "iter_param = ListParameter('n_iter', [250, 500, 1000, 2000])\n",
    "rate_param = RangeParameter('rate', 1e-4, 1e-2, step=0.75, log_base=10)\n",
    "reg_param  = RangeParameter('mu', 1e-8, 1e-2, step=1, log_base=10)\n",
    "\n",
    "disc_model = LogReg()\n",
    "\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name RandomSearch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-014e9d4ed9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name RandomSearch"
     ]
    }
   ],
   "source": [
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import LogReg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name RandomSearch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-014e9d4ed9f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name RandomSearch"
     ]
    }
   ],
   "source": [
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name ListParameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-10bf960af048>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name ListParameter"
     ]
    }
   ],
   "source": [
    "from snorkel.learning_utils import  ListParameter, RangeParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Base Python\n",
    "import cPickle, json, os, sys, warnings\n",
    "from collections import defaultdict, OrderedDict, namedtuple\n",
    "import lxml.etree as et\n",
    "\n",
    "# Scientific modules\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "warnings.filterwarnings(\"ignore\", module=\"matplotlib\")\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sparse\n",
    "from itertools import product\n",
    "from pandas import DataFrame\n",
    "\n",
    "def score(test_candidates, test_labels, test_pred, gold_candidate_set, train_marginals=None, test_marginals=None):\n",
    "    '''\n",
    "    Compute score with true recall\n",
    "    \n",
    "    :param candidates       candidate set\n",
    "    :param candidates_gold  candidate set gold (true candidate)\n",
    "    :param gold             true set gold\n",
    "    :param pred             model predictions \n",
    "    \n",
    "    '''\n",
    "    # false negatives from complete gold set (missing from candidate set)\n",
    "    gold_fn = [c for c in gold_candidate_set if c not in test_candidates]\n",
    "\n",
    "    # Print calibration plots\n",
    "    if train_marginals is not None and test_marginals is not None:\n",
    "        print \"Calibration plot:\"\n",
    "        calibration_plots(train_marginals, test_marginals, test_labels)\n",
    "    \n",
    "    # candidate match sets\n",
    "    _, _, _, m_tp, m_fp, m_tn, m_fn, m_n_t = test_scores(test_pred, test_labels, return_vals=True, verbose=True)\n",
    "\n",
    "    # model scores, augmented by missing FN set\n",
    "    prec = m_tp / float(m_tp + m_fp)\n",
    "    rec  = m_tp / float(m_tp + m_fn + len(gold_fn))\n",
    "    f1 = 2.0 * (prec * rec) / (prec + rec)\n",
    "    \n",
    "    # Corrected FN\n",
    "    fn = m_fn + len(gold_fn)\n",
    "\n",
    "    print \"========================================\"\n",
    "    print \"Recall-corrected Noise-aware Model\"\n",
    "    print \"========================================\"\n",
    "    print \"Pos. class accuracy: %s\" % (m_tp/float(m_tp+fn),)\n",
    "    print \"Neg. class accuracy: %s\" % (m_tn/float(m_tn+m_fp),)\n",
    "    print \"Corpus Precision {:.3}\".format(prec)\n",
    "    print \"Corpus Recall    {:.3}\".format(rec)\n",
    "    print \"Corpus F1        {:.3}\".format(f1)\n",
    "    print \"----------------------------------------\"\n",
    "    print \"TP: {} | FP: {} | TN: {} | FN: {}\".format(m_tp, m_fp, m_tn, fn)\n",
    "    print \"========================================\\n\"\n",
    "\n",
    "def precision(pred, gold):\n",
    "    tp = np.sum((pred == 1) * (gold == 1))\n",
    "    fp = np.sum((pred == 1) * (gold != 1))\n",
    "    return 0 if tp == 0 else float(tp) / float(tp + fp)\n",
    "\n",
    "def recall(pred, gold):\n",
    "    tp = np.sum((pred == 1) * (gold == 1))\n",
    "    p  = np.sum(gold == 1)\n",
    "    return 0 if tp == 0 else float(tp) / float(p)\n",
    "\n",
    "def f1_score(pred, gold):\n",
    "    prec = precision(pred, gold)\n",
    "    rec  = recall(pred, gold)\n",
    "    return 0 if (prec * rec == 0) else 2 * (prec * rec)/(prec + rec)\n",
    "\n",
    "def test_scores(pred, gold, return_vals=True, verbose=False):\n",
    "    \"\"\"Returns: (precision, recall, f1_score, tp, fp, tn, fn, n_test)\"\"\"\n",
    "    n_t = len(gold)\n",
    "    if np.sum(gold == 1) + np.sum(gold == -1) != n_t:\n",
    "        raise ValueError(\"Gold labels must be in {-1,1}.\")\n",
    "    tp   = np.sum((pred == 1) * (gold == 1))\n",
    "    fp   = np.sum((pred == 1) * (gold == -1))\n",
    "    tn   = np.sum((pred < 1) * (gold == -1))\n",
    "    fn   = np.sum((pred < 1) * (gold == 1))\n",
    "    prec = tp / float(tp + fp)\n",
    "    rec  = tp / float(tp + fn)\n",
    "    f1   = 2 * (prec * rec) / (prec + rec)\n",
    "\n",
    "    # Print simple report if verbose=True\n",
    "    if verbose:\n",
    "        print \"=\" * 40\n",
    "        print \"Test set size:\\t%s\" % n_t\n",
    "        print \"-\" * 40\n",
    "        print \"Pos. class accuracy: %s\" % (tp/float(tp+fn),)\n",
    "        print \"Neg. class accuracy: %s\" % (tn/float(tn+fp),)\n",
    "        print \"-\" * 40\n",
    "        print \"Precision:\\t%s\" % prec\n",
    "        print \"Recall:\\t\\t%s\" % rec\n",
    "        print \"F1 Score:\\t%s\" % f1\n",
    "        print \"-\" * 40\n",
    "        print \"TP: %s | FP: %s | TN: %s | FN: %s\" % (tp,fp,tn,fn)\n",
    "        print \"=\" * 40\n",
    "    if return_vals:\n",
    "        return prec, rec, f1, tp, fp, tn, fn, n_t\n",
    "    \n",
    "def scores_from_counts(tp, fp, tn, fn):\n",
    "    prec = float(len(tp)) / (len(tp) + len(fp)) if len(tp) > 0 else 0\n",
    "    rec = float(len(tp)) / (len(tp) + len(fn)) if len(tp) > 0 else 0\n",
    "    f1 = 2.0 * (prec * rec) / (prec + rec) if (prec + rec) > 0 else 0\n",
    "    return prec, rec, f1    \n",
    "\n",
    "def plot_prediction_probability(probs):\n",
    "    plt.hist(probs, bins=20, normed=False, facecolor='blue')\n",
    "    plt.xlim((0,1.025))\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"# Predictions\")\n",
    "\n",
    "def plot_accuracy(probs, ground_truth):\n",
    "    x = 0.1 * np.array(range(11))\n",
    "    bin_assign = [x[i] for i in np.digitize(probs, x)-1]\n",
    "    correct = ((2*(probs >= 0.5) - 1) == ground_truth)\n",
    "    correct_prob = np.array([np.mean(correct[bin_assign == p]) for p in x])\n",
    "    xc = x[np.isfinite(correct_prob)]\n",
    "    correct_prob = correct_prob[np.isfinite(correct_prob)]\n",
    "    plt.plot(x, np.abs(x-0.5) + 0.5, 'b--', xc, correct_prob, 'ro-')\n",
    "    plt.xlim((0,1))\n",
    "    plt.ylim((0,1))\n",
    "    plt.xlabel(\"Probability\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "\n",
    "def calibration_plots(train_marginals, test_marginals, gold_labels=None):\n",
    "    \"\"\"Show classification accuracy and probability histogram plots\"\"\"\n",
    "    n_plots = 3 if gold_labels is not None else 1\n",
    "    \n",
    "    # Whole set histogram\n",
    "    plt.subplot(1,n_plots,1)\n",
    "    plot_prediction_probability(train_marginals)\n",
    "    plt.title(\"(a) # Predictions (training set)\")\n",
    "\n",
    "    if gold_labels is not None:\n",
    "\n",
    "        # Hold-out histogram\n",
    "        plt.subplot(1,n_plots,2)\n",
    "        plot_prediction_probability(test_marginals)\n",
    "        plt.title(\"(b) # Predictions (test set)\")\n",
    "\n",
    "        # Classification bucket accuracy\n",
    "        plt.subplot(1,n_plots,3)\n",
    "        plot_accuracy(test_marginals, gold_labels)\n",
    "        plt.title(\"(c) Accuracy (test set)\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "ValidatedFit = namedtuple('ValidatedFit', ['w', 'P', 'R', 'F1'])\n",
    "\n",
    "\n",
    "def grid_search_plot(w_fit, mu_opt, f1_opt):\n",
    "    \"\"\" Plot validation set performance for logistic regression regularization \"\"\"\n",
    "    mu_seq = sorted(w_fit.keys())\n",
    "    p = np.ravel([w_fit[mu].P for mu in mu_seq])\n",
    "    r = np.ravel([w_fit[mu].R for mu in mu_seq])\n",
    "    f1 = np.ravel([w_fit[mu].F1 for mu in mu_seq])\n",
    "    nnz = np.ravel([np.sum(w_fit[mu].w != 0) for mu in mu_seq])    \n",
    "\n",
    "    fig, ax1 = plt.subplots()\n",
    "    \n",
    "    # Plot spread\n",
    "    ax1.set_xscale('log', nonposx='clip')    \n",
    "    ax1.scatter(mu_opt, f1_opt, marker='*', color='purple', s=500,\n",
    "                zorder=10, label=\"Maximum F1: mu={}\".format(mu_opt))\n",
    "    ax1.plot(mu_seq, f1, 'o-', color='red', label='F1 score')\n",
    "    ax1.plot(mu_seq, p, 'o--', color='blue', label='Precision')\n",
    "    ax1.plot(mu_seq, r, 'o--', color='green', label='Recall')\n",
    "    ax1.set_xlabel('log(penalty)')\n",
    "    ax1.set_ylabel('F1 score/Precision/Recall')\n",
    "    ax1.set_ylim(-0.04, 1.04)\n",
    "    for t1 in ax1.get_yticklabels():\n",
    "      t1.set_color('r')\n",
    "    \n",
    "    # Plot nnz\n",
    "    ax2 = ax1.twinx()\n",
    "    ax2.plot(mu_seq, nnz, '.:', color='gray', label='Sparsity')\n",
    "    ax2.set_ylabel('Number of non-zero coefficients')\n",
    "    ax2.set_ylim(-0.01*np.max(nnz), np.max(nnz)*1.01)\n",
    "    for t2 in ax2.get_yticklabels():\n",
    "      t2.set_color('gray')\n",
    "    \n",
    "    # Shrink plot for legend\n",
    "    box1 = ax1.get_position()\n",
    "    ax1.set_position([box1.x0, box1.y0+box1.height*0.1, box1.width, box1.height*0.9])\n",
    "    box2 = ax2.get_position()\n",
    "    ax2.set_position([box2.x0, box2.y0+box2.height*0.1, box2.width, box2.height*0.9])\n",
    "    plt.title(\"Validation for logistic regression learning\")\n",
    "    lns1, lbs1 = ax1.get_legend_handles_labels()\n",
    "    lns2, lbs2 = ax2.get_legend_handles_labels()\n",
    "    ax1.legend(lns1+lns2, lbs1+lbs2, loc='upper center', bbox_to_anchor=(0.5,-0.05),\n",
    "               scatterpoints=1, fontsize=10, markerscale=0.5)\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "class Parameter(object):\n",
    "    \"\"\"Base class for a grid search parameter\"\"\"\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "    \n",
    "    def get_all_values(self):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def draw_values(self, n):\n",
    "        return np.random.choice(self.get_all_values(), n)\n",
    "    \n",
    "class ListParameter(Parameter):\n",
    "    \"\"\"List of parameter values for searching\"\"\"\n",
    "    def __init__(self, name, parameter_list):\n",
    "        self.parameter_list = np.ravel(parameter_list)\n",
    "        super(ListParameter, self).__init__(name)\n",
    "    \n",
    "    def get_all_values(self):\n",
    "        return self.parameter_list\n",
    "    \n",
    "class RangeParameter(Parameter):\n",
    "    \"\"\"\n",
    "    Range of parameter values for searching.\n",
    "    min_value and max_value are the ends of the search range\n",
    "    If log_base is specified, scale the search range in the log base\n",
    "    step is range step size or exponent step size\n",
    "    \"\"\"\n",
    "    def __init__(self, name, min_value, max_value, step=1, log_base=None):\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.step = step\n",
    "        self.log_base = log_base\n",
    "        super(RangeParameter, self).__init__(name)\n",
    "        \n",
    "    def get_all_values(self):\n",
    "        if self.log_base:\n",
    "            min_exp = math.log(self.min_value, self.log_base)\n",
    "            max_exp = math.log(self.max_value, self.log_base)\n",
    "            exps = np.arange(min_exp, max_exp + self.step, step=self.step)\n",
    "            return np.power(self.log_base, exps)\n",
    "        return np.arange(self.min_value, self.max_value + self.step, step=self.step)\n",
    "        \n",
    "\n",
    "class GridSearch(object):\n",
    "    \"\"\"\n",
    "    Runs hyperparameter grid search over a model object with train and score methods,\n",
    "    training data (X), and training_marginals\n",
    "    Selects based on maximizing F1 score on a supplied validation set\n",
    "    Specify search space with Parameter arguments\n",
    "    \"\"\"\n",
    "    def __init__(self, model, X, training_marginals, *parameters):\n",
    "        self.model              = model\n",
    "        self.X                  = X\n",
    "        self.training_marginals = training_marginals\n",
    "        self.params             = parameters\n",
    "        self.param_names        = [param.name for param in parameters]\n",
    "        \n",
    "    def search_space(self):\n",
    "        return product(param.get_all_values() for param in self.params)\n",
    "\n",
    "    def fit(self, X_validation, validation_labels, gold_candidate_set, b=0.5, set_unlabeled_as_neg=True, **model_hyperparams):\n",
    "        \"\"\"\n",
    "        Basic method to start grid search, returns DataFrame table of results\n",
    "          b specifies the positive class threshold for calculating f1\n",
    "          set_unlabeled_as_neg is used to decide class of unlabeled cases for f1\n",
    "          Non-search parameters are set using model_hyperparamters\n",
    "        \"\"\"\n",
    "        # Iterate over the param values\n",
    "        run_stats   = []\n",
    "        param_opts  = np.zeros(len(self.param_names))\n",
    "        f1_opt      = -1.0\n",
    "        for param_vals in self.search_space():\n",
    "\n",
    "            # Set the new hyperparam configuration to test\n",
    "            for pn, pv in zip(self.param_names, param_vals):\n",
    "                model_hyperparams[pn] = pv\n",
    "            print \"=\" * 60\n",
    "            print \"Testing %s\" % ', '.join([\"%s = %0.2e\" % (pn,pv) for pn,pv in zip(self.param_names, param_vals)])\n",
    "            print \"=\" * 60\n",
    "\n",
    "            # Train the model\n",
    "            self.model.train(self.X, self.training_marginals, **model_hyperparams)\n",
    "\n",
    "            # Test the model\n",
    "            tp, fp, tn, fn = self.model.score(X_validation, validation_labels, gold_candidate_set, b, set_unlabeled_as_neg, display=False)\n",
    "            p, r, f1 = scores_from_counts(tp, fp, tn, fn)\n",
    "            run_stats.append(list(param_vals) + [p, r, f1])\n",
    "            if f1 > f1_opt:\n",
    "                w_opt      = self.model.w\n",
    "                param_opts = param_vals\n",
    "                f1_opt     = f1\n",
    "\n",
    "        # Set optimal parameter in the learner model\n",
    "        self.model.w = w_opt\n",
    "\n",
    "        # Return DataFrame of scores\n",
    "        self.results = DataFrame.from_records(run_stats, columns=self.param_names + ['Prec.', 'Rec.', 'F1'])\n",
    "        return self.results\n",
    "    \n",
    "    \n",
    "class RandomSearch(GridSearch):\n",
    "    def __init__(self, model, X, training_marginals, n, *parameters):\n",
    "        \"\"\"Search a random sample of size n from a parameter grid\"\"\"\n",
    "        self.n = n\n",
    "        super(RandomSearch, self).__init__(model, X, training_marginals, *parameters)\n",
    "        \n",
    "    def search_space(self):\n",
    "        return zip(*[param.draw_values(self.n) for param in self.params])\n",
    "\n",
    "def sparse_abs(X):\n",
    "    \"\"\"Element-wise absolute value of sparse matrix- avoids casting to dense matrix!\"\"\"\n",
    "    X_abs = X.copy()\n",
    "    if not sparse.issparse(X):\n",
    "        return abs(X_abs)\n",
    "    if sparse.isspmatrix_csr(X) or sparse.isspmatrix_csc(X):\n",
    "        X_abs.data = np.abs(X_abs.data)\n",
    "    elif sparse.isspmatrix_lil(X):\n",
    "        X_abs.data = np.array([np.abs(L) for L in X_abs.data])\n",
    "    else:\n",
    "        raise ValueError(\"Only supports CSR/CSC and LIL matrices\")\n",
    "    return X_abs\n",
    "\n",
    "\n",
    "def candidate_coverage(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates which have > 0 (non-zero) labels.**\n",
    "    \"\"\"\n",
    "    return np.where(sparse_abs(L).sum(axis=1) != 0, 1, 0).sum() / float(L.shape[0])\n",
    "\n",
    "def LF_coverage(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates that each LF labels.**\n",
    "    \"\"\"\n",
    "    return np.ravel(sparse_abs(L).sum(axis=0) / float(L.shape[0]))\n",
    "\n",
    "def candidate_overlap(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates which have > 1 (non-zero) labels.**\n",
    "    \"\"\"\n",
    "    return np.where(sparse_abs(L).sum(axis=1) > 1, 1, 0).sum() / float(L.shape[0])\n",
    "\n",
    "def LF_overlaps(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates that each LF _overlaps with other LFs on_.**\n",
    "    \"\"\"\n",
    "    L_abs = sparse_abs(L)\n",
    "    return np.ravel(np.where(L_abs.sum(axis=1) > 1, 1, 0).T * L_abs / float(L.shape[0]))\n",
    "\n",
    "def candidate_conflict(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates which have > 1 (non-zero) labels _which are not equal_.**\n",
    "    \"\"\"\n",
    "    return np.where(sparse_abs(L).sum(axis=1) != sparse_abs(L.sum(axis=1)), 1, 0).sum() / float(L.shape[0])\n",
    "\n",
    "def LF_conflicts(L):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return the **fraction of candidates that each LF _conflicts with other LFs on_.**\n",
    "    \"\"\"\n",
    "    L_abs = sparse_abs(L)\n",
    "    return np.ravel(np.where(L_abs.sum(axis=1) != sparse_abs(L.sum(axis=1)), 1, 0).T * L_abs / float(L.shape[0]))\n",
    "\n",
    "def LF_accuracies(L, labels):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate, and labels {-1,1}\n",
    "    Return the accuracy of each LF w.r.t. these labels\n",
    "    \"\"\"\n",
    "    return np.ravel(0.5*(L.T.dot(labels) / sparse_abs(L).sum(axis=0) + 1))\n",
    "\n",
    "def training_set_summary_stats(L, return_vals=True, verbose=False):\n",
    "    \"\"\"\n",
    "    Given an N x M matrix where L_{i,j} is the label given by the jth LF to the ith candidate:\n",
    "    Return simple summary statistics\n",
    "    \"\"\"\n",
    "    N, M = L.shape\n",
    "    coverage, overlap, conflict = candidate_coverage(L), candidate_overlap(L), candidate_conflict(L)\n",
    "    if verbose:\n",
    "        print \"=\" * 60\n",
    "        print \"LF Summary Statistics: %s LFs applied to %s candidates\" % (M, N)\n",
    "        print \"-\" * 60\n",
    "        print \"Coverage (candidates w/ > 0 labels):\\t\\t%0.2f%%\" % (coverage*100,)\n",
    "        print \"Overlap (candidates w/ > 1 labels):\\t\\t%0.2f%%\" % (overlap*100,)\n",
    "        print \"Conflict (candidates w/ conflicting labels):\\t%0.2f%%\" % (conflict*100,)\n",
    "        print \"=\" * 60\n",
    "    if return_vals:\n",
    "        return coverage, overlap, conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name RandomSearch",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9c8433b1ae86>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLogReg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRandomSearch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0miter_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mListParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_iter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mrate_param\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRangeParameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rate'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_base\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name RandomSearch"
     ]
    }
   ],
   "source": [
    "from snorkel.learning import LogReg\n",
    "from snorkel.learning_utils import RandomSearch, ListParameter, RangeParameter\n",
    "\n",
    "iter_param = ListParameter('n_iter', [250, 500, 1000, 2000])\n",
    "rate_param = RangeParameter('rate', 1e-4, 1e-2, step=0.75, log_base=10)\n",
    "reg_param  = RangeParameter('mu', 1e-8, 1e-2, step=1, log_base=10)\n",
    "\n",
    "disc_model = LogReg()\n",
    "\n",
    "%time F_dev = feature_manager.update(session, dev, 'Train Features', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
